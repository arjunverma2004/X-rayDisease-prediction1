{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mPkubpgNYsg",
        "outputId": "5b8c4d97-dedc-41ec-9513-9f25ebecc86f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Colab cache for faster access to the 'chest-xray-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/chest-xray-dataset\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"muhammadrehan00/chest-xray-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "1y2RWe-wNP66",
        "outputId": "f31b93d9-80d4-43d7-fa15-174aaf94c8a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ GPU Detected: /physical_device:GPU:0\n",
            "✅ Mixed Precision Enabled\n",
            "Loading datasets...\n",
            "Classes found: ['normal', 'pneumonia', 'tuberculosis']\n",
            "\n",
            "--- Initial Training with Frozen Base Model ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ densenet121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,075</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ densenet121 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │     \u001b[38;5;34m7,037,504\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m3,075\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,040,579</span> (26.86 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,040,579\u001b[0m (26.86 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,075</span> (12.01 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,075\u001b[0m (12.01 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> (26.85 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,037,504\u001b[0m (26.85 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 703ms/step - accuracy: 0.5066 - loss: 1.9594 - val_accuracy: 0.6906 - val_loss: 0.7235\n",
            "Epoch 2/10\n",
            "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 722ms/step - accuracy: 0.6611 - loss: 0.7585 - val_accuracy: 0.6152 - val_loss: 0.9310\n",
            "Epoch 3/10\n",
            "\u001b[1m 15/320\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:10\u001b[0m 623ms/step - accuracy: 0.6758 - loss: 0.7079"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, mixed_precision\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# --- 1. GPU & Memory Setup (CRITICAL) ---\n",
        "\n",
        "# Verify GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if not gpus:\n",
        "    print(\"❌ NO GPU DETECTED! Please go to Runtime > Change runtime type > T4 GPU\")\n",
        "    sys.exit() # Stop script if no GPU\n",
        "else:\n",
        "    print(f\"✅ GPU Detected: {gpus[0].name}\")\n",
        "\n",
        "# Enable Mixed Precision (Faster training, less VRAM usage on T4)\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "print(\"✅ Mixed Precision Enabled\")\n",
        "\n",
        "# --- Configuration ---\n",
        "BATCH_SIZE = 64\n",
        "IMG_SIZE = (224, 224)\n",
        "EPOCHS = 20 # Increased epochs for fine-tuning\n",
        "DATASET_PATH = \"/kaggle/input/chest-xray-dataset/\"\n",
        "\n",
        "# Get class names and create mapping outside the graph for efficiency\n",
        "def get_class_names(dataset_path):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    # Use os.listdir and filter for directories to get class names\n",
        "    return sorted([name for name in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, name))])\n",
        "\n",
        "class_names = get_class_names(DATASET_PATH)\n",
        "num_classes = len(class_names)\n",
        "class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def preprocess_image(filepath):\n",
        "    # Load the raw data from the file as a string\n",
        "    img = tf.io.read_file(filepath)\n",
        "    # Decode the image to a tensor\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    # Resize the image to the desired size\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    # EfficientNet expects input in [0, 255] range as float32\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    return img\n",
        "\n",
        "def get_label(file_path):\n",
        "    # Convert path to string tensor\n",
        "    parts = tf.strings.split(file_path, '/')\n",
        "    # The label is the second to last part of the path (e.g., 'train/NORMAL/image.jpeg')\n",
        "    label_str = parts[-2]\n",
        "    # Use tf.py_function to execute Python code (dictionary lookup) within the TensorFlow graph\n",
        "    return tf.py_function(lambda s: tf.constant(class_to_idx[s.numpy().decode('utf-8')], dtype=tf.int32),\n",
        "                          [label_str], tf.int32)\n",
        "\n",
        "def parse_image_and_label(filepath):\n",
        "    img = preprocess_image(filepath)\n",
        "    label = get_label(filepath)\n",
        "    # Set static shapes for the tensors, which is good practice with tf.py_function\n",
        "    img.set_shape((IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "    label.set_shape([]) # Scalar label\n",
        "    return img, label\n",
        "\n",
        "def configure_for_performance(ds, shuffle=True):\n",
        "    if shuffle:\n",
        "        # Shuffle with a buffer, not the whole dataset to save RAM\n",
        "        ds = ds.shuffle(buffer_size=1000)\n",
        "    ds = ds.batch(BATCH_SIZE)\n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE) # Prefetch batches to keep GPU busy\n",
        "    return ds\n",
        "\n",
        "def build_and_train_model():\n",
        "    print(\"Loading datasets...\")\n",
        "\n",
        "    train_dir = os.path.join(DATASET_PATH, 'train')\n",
        "    val_dir = os.path.join(DATASET_PATH, 'val')\n",
        "\n",
        "    # Get file paths using tf.data.Dataset.list_files for efficient listing\n",
        "    # Adjusted glob pattern to search for '*.jpg' files instead of '*.jpeg'\n",
        "    train_file_paths = tf.data.Dataset.list_files(os.path.join(train_dir, '*/*.jpg'))\n",
        "    val_file_paths = tf.data.Dataset.list_files(os.path.join(val_dir, '*/*.jpg'))\n",
        "\n",
        "    # Map preprocessing and label extraction functions in parallel\n",
        "    train_ds = train_file_paths.map(parse_image_and_label, num_parallel_calls=AUTOTUNE)\n",
        "    val_ds = val_file_paths.map(parse_image_and_label, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # Configure for performance (batching, shuffling, prefetching)\n",
        "    train_ds = configure_for_performance(train_ds, shuffle=True)\n",
        "    val_ds = configure_for_performance(val_ds, shuffle=False)\n",
        "\n",
        "    print(f\"Classes found: {class_names}\")\n",
        "\n",
        "    # --- Data Augmentation ---\n",
        "    data_augmentation = tf.keras.Sequential([\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.1),\n",
        "    ])\n",
        "\n",
        "    # --- Model Build (EfficientNetB0) ---\n",
        "    base_model = tf.keras.applications.EfficientNetB0(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
        "    )\n",
        "\n",
        "    # Original compile with frozen base for initial training\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "    x = data_augmentation(inputs)\n",
        "    x = base_model(x, training=False) # Important: set training=False to keep BatchNormalization layers frozen\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Initial Training with Frozen Base Model ---\")\n",
        "    model.summary()\n",
        "\n",
        "    # Optional: Add EarlyStopping to save time if model stops improving\n",
        "    callback_frozen = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    history_frozen = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=10, # Fewer epochs for initial training\n",
        "        callbacks=[callback_frozen]\n",
        "    )\n",
        "\n",
        "    # --- Fine-tuning: Unfreeze top layers of the base model ---\n",
        "    print(\"\\n--- Fine-tuning: Unfreezing top layers of EfficientNet ---\")\n",
        "    base_model.trainable = True\n",
        "\n",
        "    # Unfreeze all layers except for the batch normalization layers\n",
        "    for layer in base_model.layers:\n",
        "        if isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = False\n",
        "        else:\n",
        "            layer.trainable = True\n",
        "\n",
        "    # Recompile model with a lower learning rate for fine-tuning\n",
        "    # It's important to use a very small learning rate for fine-tuning\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), # Very low learning rate\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    print(\"\\nStarting fine-tuning...\")\n",
        "    callback_finetune = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    history_finetune = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=EPOCHS, # Use remaining epochs or more\n",
        "        callbacks=[callback_finetune]\n",
        "    )\n",
        "\n",
        "    # --- Save ---\n",
        "    model.save('chest_xray_model_finetuned.keras')\n",
        "    print(\"Model saved as chest_xray_model_finetuned.keras\")\n",
        "\n",
        "    with open('class_names.txt', 'w') as f:\n",
        "        f.write('\\n'.join(class_names))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    build_and_train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('grand_slam_best_model.keras')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
